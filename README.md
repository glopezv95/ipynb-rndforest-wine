<h1 id="header">Machine Learning classification model analysis</h1>

This project focuses on analysing the performance of various Machine Learning models available in python's [scikit-learn](https://scikit-learn.org/stable/index.html) package when trying to predict wine classification. 

The dataset used throughout the project is the [UCI ML Wine Dataset](https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data), and it has been imported using the `sklearn.datasets` module.

<h2 id="toc">Table of contents</h2>

[Project configuration](#config)
- [Create a virtual environment](#venvcreate)
- [Activate the virtual environment](#venvactivate)
- [Install dependencies](#dependencies)

[Project structure](#structure)
- [Auxiliary folder](#auxfolder)
  - [const.py](#const)
  - [functions.py](#functions)
- [main.py](#main)
- [optimisation.ipynb](#optimisation)
- [requirements.txt](#requirements)

[Running the project](#run)<br>
[Deploying the project](#deploy)

<h2 id="config">Project configuration</h2>

In order for the project to run properly, a series of steps need to be done;

<h3 id="venvcreate">Create a virtual environment</h3>

```
python -m venv venv
```

<h3 id="venvactivate">Activate the virtual environment</h3>

Using PowerShell
```
venv/scripts/activate
```
Using bash
```
source venv/bin/activate
```

<h3 id="dependencies">Install dependencies</h3>

```
pip install -r requirements.txt
```

<h2 id="structure">Project structure</h2>

```
PROJECT DIRECTORY
├─ auxiliary
│  ├─ const.py
│  └─ functions.py
├─ main.py
├─ optimisation.ipynb
├─ README.md
├─ requirements.txt
└─ venv
   ├─ *
```

<h3 id="auxfolder"><code>auxiliary</code> folder</h3>

<h4 id="const"><code>const.py</code></h4>

This file contains constant miscellaneous variables used throughout the project, including the <strong>random seed</strong>, the <strong>title</strong> and <strong>subtitle</strong> of the main script, and the <strong>url</strong> to the database raw data.

<h4 id="functions"><code>functions.py</code></h4>

This file contains all the functions used on the main script to perform the <strong>extraction</strong> and <strong>transformation</strong> of the dataset, as well as to <strong>predict</strong> data imported using the main script.

<h3 id="main"><code>main.py</code> script</h3>

This is the python script from where the project is run.

<h3 id="optimisation"><code>optimisation.ipynb</code> notebook</h3>

This notebook includes all the preprocessing done on the data in order to select the most adequate Machine Learning model for the dataset. This includes;

- **Data analysis**. Data loading and describing. Feature analysis.
- **Data preparation**. PCA dimension reduction, train/test split and feature normalising.
- **Model selection**. K Nearest Neighbors, Ridge Classifier and Random Forest Classifier performance testing.
- **Selected model description**.

<h3 id="requirements"><code>requirements.txt</code></h3>

This `.txt` includes all the necessary packages in order for the main script to run properly.

<h2 id="run">Running the project</h2>

In order to utilise the model generated by the project, the `main.py` script needs to be run. On the shell, the following snippet needs to be written;
```
python main.py
```

<h2 id="deploy">Deploying the project</h2>

In order to deploy the project and automatically create a virtual environment, activate it, install dependencies and run the project, the `deploy.py` script needs to be run. On the shell, the following snippet needs to be written;
```
python deploy.py
```

[Back up](#header)